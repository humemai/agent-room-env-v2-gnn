{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# disable logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "from agent.dqn import DQNAgent\n",
    "\n",
    "agent = DQNAgent(\n",
    "    default_root_dir=\"./training-results/TRASH\",\n",
    "    num_iterations=200,\n",
    "    replay_buffer_size=150,\n",
    "    warm_start=100,\n",
    "    capacity={\"episodic\": 4, \"semantic\": 4, \"short\": 10}\n",
    ")\n",
    "# agent.fill_replay_buffer()\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.dqn.utils import MultiAgentReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.dqn.utils import MultiAgentReplayBuffer\n",
    "import numpy as np\n",
    "import torch\n",
    "device = \"cpu\"\n",
    "\n",
    "buffer_combined = MultiAgentReplayBuffer(\n",
    "    agent.replay_buffer_mm, agent.replay_buffer_explore\n",
    ")\n",
    "batch_mm, batch_explore = buffer_combined.sample_batch(sample_same_index=True)\n",
    "\n",
    "assert np.array_equal(\n",
    "    batch_mm[\"rews\"], batch_explore[\"rews\"]\n",
    "), \"Rewards are not the same.\"\n",
    "assert np.array_equal(\n",
    "    batch_mm[\"done\"], batch_explore[\"done\"]\n",
    "), \"Dones are not the same.\"\n",
    "\n",
    "s_mm = batch_mm[\"obs\"]\n",
    "s_next_mm = batch_mm[\"next_obs\"]\n",
    "a_mm = batch_mm[\"acts\"]\n",
    "r_mm = torch.FloatTensor(batch_mm[\"rews\"].reshape(-1, 1)).to(device)\n",
    "d_mm = torch.FloatTensor(batch_mm[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "s_explore = batch_explore[\"obs\"]\n",
    "s_next_explore = batch_explore[\"next_obs\"]\n",
    "a_explore = batch_explore[\"acts\"]\n",
    "r_explore = torch.FloatTensor(batch_explore[\"rews\"].reshape(-1, 1)).to(device)\n",
    "d_explore = torch.FloatTensor(batch_explore[\"done\"].reshape(-1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the array of lists into a single list of integers\n",
    "a_explore = [item[0] for item in a_explore]  # Extract the single element from each sublist\n",
    "\n",
    "# # Convert the list to a PyTorch tensor\n",
    "# tensor = torch.tensor(flattened_list)\n",
    "\n",
    "# # Reshape the tensor to have the shape (32, 1)\n",
    "# reshaped_tensor = tensor.view(32, 1)\n",
    "\n",
    "# # Print the reshaped tensor\n",
    "# # print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [1],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [4],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [1],\n",
       "        [4],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([item[0] for item in a_explore]).reshape(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([4]), list([4]), list([0]), list([3]), list([0]), list([3]),\n",
       "       list([1]), list([2]), list([3]), list([2]), list([4]), list([0]),\n",
       "       list([4]), list([2]), list([1]), list([2]), list([4]), list([4]),\n",
       "       list([2]), list([0]), list([3]), list([2]), list([0]), list([0]),\n",
       "       list([1]), list([4]), list([2]), list([2]), list([3]), list([4]),\n",
       "       list([0]), list([4])], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert it to tensor\n",
    "a_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_explore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.LongTensor(a_explore.reshape(-1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# Pad indices to the maximum length, in this case 3, using a padding value that is invalid (-1 or could use max column index if -1 is problematic)\n",
    "padded_indices = torch.tensor([\n",
    "    [0, -1, -1],\n",
    "    [1, 2, -1],\n",
    "    [0, 1, 2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.gather to gather elements from the tensor based on the padded index\n",
    "# Mask to ignore padded values (-1 index will cause an error, thus handle via valid range or other methods)\n",
    "valid_mask = padded_indices >= 0\n",
    "valid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 2, 0],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_indices[~valid_mask] = 0  # Temporarily replace invalid indices with 0 to avoid runtime error\n",
    "padded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [5, 6, 4],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered = torch.gather(tensor, dim=1, index=padded_indices)\n",
    "gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, -1, -1],\n",
       "        [ 5,  6, -1],\n",
       "        [ 7,  8,  9]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered[~valid_mask] = -1  # Replace output from invalid indices with -1 or another flag value\n",
    "gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2], [2, -1]]).max(dim=1, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1]).detach().cpu().numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [5, 4],\n",
      "        [9, 8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# Create an index tensor\n",
    "index = torch.tensor([[0, 2],\n",
    "                      [1, 0],\n",
    "                      [2, 1]])\n",
    "\n",
    "# Use torch.gather to gather elements from the tensor based on the index\n",
    "gathered = torch.gather(tensor, dim=1, index=index)\n",
    "\n",
    "print(gathered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0]), list([1, 2]), list([0, 1, 2])], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.array([{}]*3)\n",
    "index[0] = [0]\n",
    "index[1] = [1,2]\n",
    "index[2] = [0,1,2]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.tensor(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:168: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# disable logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "from agent.dqn import DQNAgent\n",
    "import gymnasium as gym\n",
    "import random\n",
    "from humemai.policy import manage_memory, encode_all_observations\n",
    "\n",
    "agent = DQNAgent(\n",
    "    default_root_dir=\"./training-results/TRASH\",\n",
    "    num_iterations=100,\n",
    "    replay_buffer_size=100,\n",
    "    warm_start=100,\n",
    ")\n",
    "\n",
    "env = gym.make(\"room_env:RoomEnv-v2\", room_size=\"l\")\n",
    "observations, info = env.reset()\n",
    "rewards = 0\n",
    "\n",
    "# while True:\n",
    "#     observations, reward, done, truncated, info = env.step(\n",
    "#         (\n",
    "#             [\"random answer\"] * len(observations[\"questions\"]),\n",
    "#             random.choice([\"north\", \"east\", \"south\", \"west\", \"stay\"]),\n",
    "#         )\n",
    "#     )\n",
    "#     rewards += reward\n",
    "#     if done or truncated:\n",
    "#         break\n",
    "\n",
    "agent.fill_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer_mm.sample_batch()[\"acts\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{   'episodic': {   '_frozen': False,\n",
       "    'capacity': 16,\n",
       "    'entries': [   ],\n",
       "    'remove_duplicates': False,\n",
       "    'type': 'episodic'},\n",
       "    'semantic': {   '_frozen': False,\n",
       "    'capacity': 16,\n",
       "    'entries': [   ],\n",
       "    'type': 'semantic'},\n",
       "    'short': {   '_frozen': False,\n",
       "    'capacity': 10,\n",
       "    'entries': [   [   'room_000',\n",
       "                       'north',\n",
       "                       'wall',\n",
       "                       0],\n",
       "                   [   'room_000',\n",
       "                       'east',\n",
       "                       'room_001',\n",
       "                       0],\n",
       "                   [   'room_000',\n",
       "                       'south',\n",
       "                       'wall',\n",
       "                       0],\n",
       "                   [   'room_000',\n",
       "                       'west',\n",
       "                       'wall',\n",
       "                       0],\n",
       "                   [   'agent',\n",
       "                       'atlocation',\n",
       "                       'room_000',\n",
       "                       0]],\n",
       "    'type': 'short'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory_systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 11:30:46.669 INFO memory - add: memory entry ['room_000', 'north', 'wall', 0] added. Now there are in total of 1 memories!\n",
      "2024-05-03 11:30:46.672 INFO memory - forget: ['room_000', 'north', 'wall', 0] forgotten!\n",
      "2024-05-03 11:30:46.673 INFO memory - add: memory entry ['room_000', 'east', 'room_001', 1] added. Now there are in total of 1 memories!\n",
      "2024-05-03 11:30:46.674 INFO memory - forget: ['room_000', 'east', 'room_001', 0] forgotten!\n",
      "2024-05-03 11:30:46.675 INFO memory - forget: ['room_000', 'south', 'wall', 0] forgotten!\n",
      "2024-05-03 11:30:46.676 INFO memory - add: memory entry ['room_000', 'west', 'wall', 0] added. Now there are in total of 2 memories!\n",
      "2024-05-03 11:30:46.676 INFO memory - forget: ['room_000', 'west', 'wall', 0] forgotten!\n",
      "2024-05-03 11:30:46.677 INFO memory - add: memory entry ['agent', 'atlocation', 'room_000', 1] added. Now there are in total of 2 memories!\n",
      "2024-05-03 11:30:46.678 INFO memory - forget: ['agent', 'atlocation', 'room_000', 0] forgotten!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room_000', 'north', 'wall', 0]\n",
      "['room_000', 'east', 'room_001', 0]\n",
      "['room_000', 'south', 'wall', 0]\n",
      "['room_000', 'west', 'wall', 0]\n",
      "['agent', 'atlocation', 'room_000', 0]\n"
     ]
    }
   ],
   "source": [
    "for a_mm_, mem_short in zip([0, 1, 2, 0, 1], agent.memory_systems.short):\n",
    "    print(mem_short)\n",
    "    manage_memory(agent.memory_systems, agent.action_mm2str[a_mm_], mem_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{   'episodic': {   '_frozen': False,\n",
       "    'capacity': 16,\n",
       "    'entries': [   [   'room_000',\n",
       "                       'north',\n",
       "                       'wall',\n",
       "                       0],\n",
       "                   [   'room_000',\n",
       "                       'west',\n",
       "                       'wall',\n",
       "                       0]],\n",
       "    'remove_duplicates': False,\n",
       "    'type': 'episodic'},\n",
       "    'semantic': {   '_frozen': False,\n",
       "    'capacity': 16,\n",
       "    'entries': [   [   'room_000',\n",
       "                       'east',\n",
       "                       'room_001',\n",
       "                       1],\n",
       "                   [   'agent',\n",
       "                       'atlocation',\n",
       "                       'room_000',\n",
       "                       1]],\n",
       "    'type': 'semantic'},\n",
       "    'short': {   '_frozen': False,\n",
       "    'capacity': 10,\n",
       "    'entries': [   ],\n",
       "    'type': 'short'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory_systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from agent.dqn.utils import ReplayBuffer\n",
    "import random\n",
    "\n",
    "buffer = ReplayBuffer(8, 4)\n",
    "\n",
    "for _ in range(6):\n",
    "\n",
    "    rand_dict_1 = {str(i): str(random.randint(0, 10)) for i in range(3)}\n",
    "    rand_dict_2 = {str(i): str(random.randint(0, 10)) for i in range(3)}\n",
    "    action = [i for i in range(random.randint(1, 10))]\n",
    "    buffer.store(\n",
    "        *[\n",
    "            rand_dict_1,\n",
    "            action,\n",
    "            random.choice([-1, 1]),\n",
    "            rand_dict_2,\n",
    "            random.choice([False, True]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs': array([{'0': '3', '1': '4', '2': '5'}, {'0': '5', '1': '1', '2': '0'},\n",
       "        {'0': '9', '1': '6', '2': '2'}, {'0': '7', '1': '2', '2': '4'}],\n",
       "       dtype=object),\n",
       " 'next_obs': array([{'0': '5', '1': '0', '2': '5'}, {'0': '5', '1': '1', '2': '9'},\n",
       "        {'0': '5', '1': '8', '2': '4'}, {'0': '6', '1': '9', '2': '4'}],\n",
       "       dtype=object),\n",
       " 'acts': array([list([0, 1, 2, 3, 4, 5]), list([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       "        list([0, 1]), list([0])], dtype=object),\n",
       " 'rews': array([ 1., -1., -1.,  1.], dtype=float32),\n",
       " 'done': array([0., 1., 1., 0.], dtype=float32)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = buffer.sample_batch()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 1, 2, 3, 4, 5, 6]), list([0, 1, 2]),\n",
       "       list([0, 1, 2, 3, 4, 5, 6, 7]), list([0, 1, 2, 3])], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"acts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"acts\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"acts\"][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-room-env-v2-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
