{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nll_loss_nd(): argument 'target' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 83\u001b[0m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 83\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/torch/nn/functional.py:2760\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2759\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: nll_loss_nd(): argument 'target' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class GCNConv(\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool | None = None,\n",
    "        normalize: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs: Any\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, num_outputs):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_outputs)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Pool node features within each graph to a single vector\n",
    "        # x = global_mean_pool(x, batch)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generate some example data\n",
    "def create_random_graph_data(\n",
    "    num_node_features, num_classes=None, min_nodes=5, max_nodes=20\n",
    "):\n",
    "    num_nodes = np.random.randint(\n",
    "        min_nodes, max_nodes + 1\n",
    "    )  # Randomly choose the number of nodes\n",
    "    edge_prob = 0.2  # Probability of edge creation between any two nodes\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j and np.random.rand() < edge_prob:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = (\n",
    "        torch.tensor(edge_index).t().contiguous()\n",
    "    )  # Transpose and make contiguous\n",
    "    x = torch.randn(num_nodes, num_node_features)  # Node features\n",
    "    # y = torch.randint(0, num_classes, (1,)).item()  # Graph-level label\n",
    "    # return Data(x=x, edge_index=edge_index, y=y)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "num_graphs = 4\n",
    "\n",
    "# Use the new function to create a dataset with more varied graph sizes\n",
    "graphs = [create_random_graph_data(3, 2) for _ in range(num_graphs)]\n",
    "\n",
    "# DataLoader for batching graphs\n",
    "loader = DataLoader(graphs, batch_size=4, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(num_features=3, num_outputs=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "        print(out.shape)\n",
    "\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[13, 3], edge_index=[2, 29]),\n",
       " Data(x=[14, 3], edge_index=[2, 37]),\n",
       " Data(x=[16, 3], edge_index=[2, 43]),\n",
       " Data(x=[19, 3], edge_index=[2, 68])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  4,\n",
       "          4,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  9,  9,\n",
       "         10, 10, 10, 11, 11, 11, 11, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
       "         14, 15, 16, 16, 16, 16, 16, 17, 17, 17, 18, 18, 18, 18],\n",
       "        [ 1,  6,  2,  4,  5,  8, 14, 17, 18,  0,  5, 10,  6, 14,  0,  5,  7,  8,\n",
       "         10,  1,  2,  3,  4, 13, 16,  0,  1, 11, 17,  2,  4,  5,  8, 17,  0, 17,\n",
       "          5,  8, 18,  3,  4,  5, 17,  5, 18,  4, 11, 12, 16, 17,  2,  3,  9, 12,\n",
       "         16, 12,  2,  7,  8, 10, 15,  4, 10, 12,  5,  6, 15, 17]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[-1].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[62, 3], edge_index=[2, 177], batch=[62], ptr=[5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1690, -1.0338, -1.6202],\n",
       "        [-0.2585, -0.7059, -0.1570],\n",
       "        [ 1.2097,  0.3235, -0.2836],\n",
       "        [ 0.6167, -0.2658,  0.5984],\n",
       "        [ 1.6300, -1.6904, -0.2952],\n",
       "        [ 1.4837, -0.8730,  0.3657],\n",
       "        [-0.3554,  0.6896, -0.7299],\n",
       "        [-0.8573, -1.0838, -0.4775],\n",
       "        [-0.0835, -0.0748,  0.1922],\n",
       "        [ 0.2450,  0.0071, -0.4362],\n",
       "        [-0.7499,  0.6503, -0.0319],\n",
       "        [-0.6749,  2.5527, -1.4721],\n",
       "        [ 0.1698, -0.6225,  1.0252],\n",
       "        [ 1.0068, -0.0274, -1.0398],\n",
       "        [ 0.3309, -0.7549, -0.9624],\n",
       "        [ 0.7005,  1.1697,  0.0126],\n",
       "        [-0.5175,  1.3866, -1.8906],\n",
       "        [-1.4835,  1.0586, -1.2979],\n",
       "        [ 0.8968,  1.6175, -0.6017],\n",
       "        [ 0.1674,  0.7094, -0.6425],\n",
       "        [ 1.0856,  0.6375,  2.6912],\n",
       "        [ 2.5122, -1.5671, -0.0251],\n",
       "        [-1.0388,  0.5314, -1.0635],\n",
       "        [-1.6514,  0.9155, -1.0362],\n",
       "        [-0.6094, -0.2221, -0.7273],\n",
       "        [-0.8373, -1.0480,  0.7659],\n",
       "        [ 0.9466,  2.3291, -0.5461],\n",
       "        [ 0.7777,  0.4165,  0.3844],\n",
       "        [ 0.6807,  0.0341, -2.0158],\n",
       "        [-1.6840, -2.5393,  1.0344],\n",
       "        [-1.6322, -0.4337,  0.5659],\n",
       "        [-0.1021,  1.0610, -0.2451],\n",
       "        [-0.1263,  0.6509, -1.4053],\n",
       "        [ 0.7660, -0.3670, -0.3658],\n",
       "        [-1.2226, -0.6082, -0.1999],\n",
       "        [ 0.3717, -0.1129,  0.1560],\n",
       "        [-0.3206, -0.9288, -0.0496],\n",
       "        [-0.7479, -0.6788, -0.2501],\n",
       "        [ 0.6544,  0.6573,  0.5829],\n",
       "        [ 1.1646,  0.4875,  0.4847],\n",
       "        [ 1.2972, -1.3073, -0.3385],\n",
       "        [-0.4399,  1.2147,  0.1450],\n",
       "        [-0.1467, -0.1614,  0.1905],\n",
       "        [-0.5129, -0.1620, -0.8557],\n",
       "        [ 0.0797, -1.8051,  0.4999],\n",
       "        [-0.7245,  2.1546,  0.5195],\n",
       "        [-0.7619,  0.8291,  0.7271],\n",
       "        [-0.1111,  0.0169, -1.8393],\n",
       "        [ 0.9659,  0.6337, -2.2659],\n",
       "        [ 0.7368, -0.6495,  2.1885],\n",
       "        [-0.1997, -1.0312,  0.5321],\n",
       "        [-0.7653, -1.0215,  0.0823],\n",
       "        [ 0.0318,  1.2432,  1.9576],\n",
       "        [ 1.7945,  0.3759, -0.1630],\n",
       "        [ 2.3524, -0.3239, -0.9942],\n",
       "        [-1.3475,  1.5164,  0.3604],\n",
       "        [ 0.9255,  0.5149, -0.1016],\n",
       "        [ 1.7082, -1.3966, -0.0328],\n",
       "        [-0.7483, -0.9412, -0.0710],\n",
       "        [ 0.1300,  0.5114, -0.0622],\n",
       "        [ 0.4933, -0.3620,  0.2901],\n",
       "        [ 0.1815,  0.7082, -1.2427]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  2,  3,  3,  3,  4,  4,  5,  5,  6,  6,  6,  6,  7,  7,  8,\n",
       "          8,  8,  8,  9,  9, 10, 10, 11, 11, 11, 12, 13, 13, 13, 14, 14, 15, 15,\n",
       "         16, 16, 16, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 20, 20, 20, 21, 21,\n",
       "         21, 21, 23, 23, 23, 24, 25, 25, 25, 26, 26, 26, 27, 27, 27, 27, 28, 28,\n",
       "         28, 29, 30, 30, 30, 31, 31, 31, 32, 32, 32, 33, 33, 33, 34, 35, 35, 36,\n",
       "         36, 37, 37, 37, 38, 38, 38, 38, 38, 39, 39, 40, 40, 40, 41, 42, 42, 42,\n",
       "         42, 43, 43, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 47, 47, 47,\n",
       "         47, 47, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 50, 50, 50, 50, 51, 52,\n",
       "         52, 53, 53, 53, 54, 54, 54, 54, 55, 55, 56, 56, 56, 56, 56, 57, 57, 57,\n",
       "         57, 57, 58, 59, 59, 59, 59, 59, 60, 60, 60, 61, 61, 61, 61],\n",
       "        [ 1,  3, 12,  8,  0,  4, 11,  6,  9,  4, 11,  0,  1,  2,  8,  1,  2,  5,\n",
       "          7, 10, 12,  0,  7,  9, 11,  5,  9, 12,  2, 24, 25, 26, 13, 20, 13, 19,\n",
       "         13, 14, 15, 20, 24, 16, 24, 14, 16, 17, 23, 16, 21, 13, 14, 23, 13, 14,\n",
       "         19, 23, 17, 18, 20, 14, 15, 20, 23, 18, 19, 21, 29, 35, 36, 42, 33, 35,\n",
       "         41, 37, 29, 31, 42, 32, 39, 40, 28, 30, 39, 29, 38, 40, 40, 27, 38, 28,\n",
       "         42, 30, 34, 35, 28, 30, 31, 34, 41, 36, 37, 27, 32, 36, 29, 29, 30, 36,\n",
       "         37, 44, 49, 45, 47, 48, 51, 57, 60, 61, 43, 48, 53, 49, 57, 43, 48, 50,\n",
       "         51, 53, 44, 45, 46, 47, 56, 59, 43, 44, 54, 60, 45, 47, 48, 51, 60, 43,\n",
       "         60, 48, 51, 61, 46, 47, 48, 60, 48, 61, 47, 54, 55, 59, 60, 45, 46, 52,\n",
       "         55, 59, 55, 45, 50, 51, 53, 58, 47, 53, 55, 48, 49, 58, 60]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
