{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example data (inputs and targets)\n",
    "X, Y = torch.randn((100, 10), requires_grad=False), torch.randn(100, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "W1 = torch.randn(2, 10, requires_grad=True)\n",
    "W2 = torch.randn(2, requires_grad=True)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.SGD([W1, W2], lr=learning_rate)\n",
    "\n",
    "loss_all = []\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    for i in range(Y.shape[0]):\n",
    "        y_pred1 = torch.matmul(W1, X[i])\n",
    "        y_pred2 = torch.matmul(W2, y_pred1)\n",
    "\n",
    "        loss = (y_pred2 - Y[i]).pow(2).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        loss_all.append(loss.detach().cpu().item())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_all)\n",
    "loss_all[0], loss_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "W1 = torch.randn(2, 10, requires_grad=True)\n",
    "W2 = torch.randn(2, requires_grad=True)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.SGD([W1, W2], lr=learning_rate)\n",
    "\n",
    "loss_all = []\n",
    "\n",
    "for _ in range(100):\n",
    "    y_pred1_all = []\n",
    "    for i in range(Y.shape[0]):\n",
    "        y_pred1 = torch.matmul(W1, X[i])\n",
    "        y_pred1_all.append(y_pred1)\n",
    "\n",
    "    for idx, y_pred1 in enumerate(y_pred1_all):\n",
    "        y_pred2 = torch.matmul(W2, y_pred1)\n",
    "\n",
    "        loss = (y_pred2 - Y[idx]).pow(2).sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        loss_all.append(loss.detach().cpu().item())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_all)\n",
    "loss_all[0], loss_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example data (inputs and targets)\n",
    "x1, y1 = torch.randn(10, requires_grad=False), torch.randn(1, requires_grad=False)\n",
    "x2, y2 = torch.randn(10, requires_grad=False), torch.randn(1, requires_grad=False)\n",
    "\n",
    "# Model parameters\n",
    "W = torch.randn(1, 10, requires_grad=True)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
    "# print(W)\n",
    "\n",
    "for _ in range(100):\n",
    "    y_pred1 = torch.matmul(W, x1)\n",
    "    y_pred2 = torch.matmul(W, x2)\n",
    "\n",
    "    loss = (y_pred1 - y1).pow(2).sum()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(W)\n",
    "\n",
    "    loss = (y_pred2 - y2).pow(2).sum()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(W)\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "# Step 2: Define the GNN Model\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_node_features: int):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Step 1: Generate a Synthetic Graph\n",
    "# Node features\n",
    "x = torch.tensor([[1, 0], [0, 1], [1, 1], [1, 0]], dtype=torch.float)\n",
    "# Edges\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 0, 2],\n",
    "                           [1, 0, 3, 2, 2, 0]], dtype=torch.long)\n",
    "# Edge labels for classification\n",
    "edge_label = torch.tensor([0, 1, 0, 1, 1, 0], dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "model = GCN(num_node_features=data.num_node_features)\n",
    "\n",
    "# Edge classifier: A simple linear layer\n",
    "# Assuming we concatenate two node embeddings\n",
    "edge_classifier = torch.nn.Linear(16 * 2, 2)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(edge_classifier.parameters()), lr=0.01)\n",
    "\n",
    "# Step 3: Training Loop\n",
    "for epoch in range(100):\n",
    "    node_embeddings = model(data)\n",
    "\n",
    "    # node_embeddings.shape == torch.Size([4, 16])\n",
    "\n",
    "    # Get embeddings of both source and target nodes of each edge\n",
    "    source_embeddings = node_embeddings[data.edge_index[0]]\n",
    "    target_embeddings = node_embeddings[data.edge_index[1]]\n",
    "\n",
    "    # Edge classification: Here we concatenate source and target embeddings\n",
    "    edge_embeddings = torch.cat([source_embeddings, target_embeddings], dim=1)\n",
    "    edge_pred = edge_classifier(edge_embeddings)\n",
    "\n",
    "    loss = F.cross_entropy(edge_pred, edge_label)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    _, pred = torch.max(edge_pred, dim=1)\n",
    "    correct = pred.eq(edge_label).sum().item()\n",
    "    accuracy = correct / edge_label.size(0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Synthetic Graph Data Setup (including node features, edges, and edge labels)\n",
    "x = torch.tensor([[1, 0], [0, 1], [1, 1], [1, 0]],\n",
    "                 dtype=torch.float)  # Node features\n",
    "edge_index = torch.tensor(\n",
    "    [[0, 1, 2, 3, 0, 2], [1, 0, 3, 2, 2, 0]], dtype=torch.long\n",
    ")  # Edges\n",
    "edge_label = torch.tensor(\n",
    "    [0, 1, 0, 1, 1, 0], dtype=torch.long\n",
    ")  # Edge labels for classification\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "# EnhancedGCN Model Definition with Learnable Embeddings\n",
    "class EnhancedGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_node_features, num_embedding_features):\n",
    "        super(EnhancedGCN, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(num_nodes, num_embedding_features)\n",
    "        self.embeddings.weight.data.uniform_(0, 1)  # Initialize embeddings\n",
    "\n",
    "        self.conv1 = GCNConv(num_embedding_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        node_indices = torch.arange(\n",
    "            0, x.size(0), dtype=torch.long, device=x.device)\n",
    "        node_embeddings = self.embeddings(node_indices)\n",
    "\n",
    "        # x = torch.cat([x, node_embeddings], dim=1)  # Concatenate original features with embeddings\n",
    "        # x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv1(node_embeddings, edge_index))\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model and Optimizer Setup\n",
    "num_nodes = data.num_nodes\n",
    "num_node_features = data.num_features\n",
    "num_embedding_features = 5  # Example additional embedding size\n",
    "model = EnhancedGCN(num_nodes, num_node_features, num_embedding_features)\n",
    "\n",
    "edge_classifier = torch.nn.Linear(\n",
    "    16 * 2, 2\n",
    ")  # Classifier for the concatenated node embeddings\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(edge_classifier.parameters()), lr=0.01\n",
    ")\n",
    "\n",
    "# Training Loop with Accuracy Calculation for Edge Classification\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    node_embeddings = model(data)\n",
    "\n",
    "    source_embeddings = node_embeddings[data.edge_index[0]]\n",
    "    target_embeddings = node_embeddings[data.edge_index[1]]\n",
    "    edge_embeddings = torch.cat([source_embeddings, target_embeddings], dim=1)\n",
    "\n",
    "    edge_pred = edge_classifier(edge_embeddings)\n",
    "    loss = F.cross_entropy(edge_pred, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    _, pred = torch.max(edge_pred, dim=1)\n",
    "    correct = pred.eq(edge_label).sum().item()\n",
    "    accuracy = correct / edge_label.size(0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class EnhancedGCNWithEdgeClassification(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_node_features, num_embedding_features, out_channels):\n",
    "        super(EnhancedGCNWithEdgeClassification, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(num_nodes, num_embedding_features)\n",
    "        self.embeddings.weight.data.uniform_(0, 1)  # Initialize embeddings\n",
    "\n",
    "        self.conv1 = GCNConv(num_node_features + num_embedding_features, 16)\n",
    "        self.conv2 = GCNConv(16, out_channels)\n",
    "\n",
    "        # Instead of a separate edge classifier, incorporate it into the GNN model\n",
    "        # Assuming binary classification for edges\n",
    "        self.edge_classifier = torch.nn.Linear(out_channels * 2, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        node_indices = torch.arange(\n",
    "            0, x.size(0), dtype=torch.long, device=x.device)\n",
    "        node_embeddings = self.embeddings(node_indices)\n",
    "        # Concatenate original features with embeddings\n",
    "        x = torch.cat([x, node_embeddings], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Now, for each edge, use the node embeddings to predict edge labels\n",
    "        source_embeddings = x[edge_index[0]]\n",
    "        target_embeddings = x[edge_index[1]]\n",
    "        edge_embeddings = torch.cat(\n",
    "            [source_embeddings, target_embeddings], dim=1)\n",
    "        edge_pred = self.edge_classifier(edge_embeddings)\n",
    "\n",
    "        return edge_pred\n",
    "\n",
    "\n",
    "# Parameters and Data Initialization\n",
    "num_nodes = data.num_nodes\n",
    "num_node_features = data.num_features\n",
    "num_embedding_features = 5  # Example additional embedding size\n",
    "out_channels = 16  # Example size for the node embeddings used in edge predictions\n",
    "\n",
    "model = EnhancedGCNWithEdgeClassification(\n",
    "    num_nodes, num_node_features, num_embedding_features, out_channels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assume edge_index, x, and edge_label are defined as in the previous examples\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Training Loop with the Adjusted Model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    edge_pred = model(data)  # The model now directly outputs edge predictions\n",
    "    loss = F.cross_entropy(edge_pred, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    _, pred = torch.max(edge_pred, dim=1)\n",
    "    correct = pred.eq(edge_label).sum().item()\n",
    "    accuracy = correct / edge_label.size(0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_outputs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_outputs)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Pool node features within each graph to a single vector\n",
    "        # x = global_mean_pool(x, batch)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generate some example data\n",
    "def create_random_graph_data(num_node_features, num_classes, min_nodes=5, max_nodes=20):\n",
    "    num_nodes = np.random.randint(\n",
    "        min_nodes, max_nodes + 1\n",
    "    )  # Randomly choose the number of nodes\n",
    "    edge_prob = 0.2  # Probability of edge creation between any two nodes\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j and np.random.rand() < edge_prob:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = (\n",
    "        torch.tensor(edge_index).t().contiguous()\n",
    "    )  # Transpose and make contiguous\n",
    "    x = torch.randn(num_nodes, num_node_features)  # Node features\n",
    "    y = torch.randint(0, num_classes, (1,)).item()  # Graph-level label\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "\n",
    "num_graphs = 20\n",
    "\n",
    "# Use the new function to create a dataset with more varied graph sizes\n",
    "graphs = [create_random_graph_data(3, 2) for _ in range(num_graphs)]\n",
    "\n",
    "# DataLoader for batching graphs\n",
    "loader = DataLoader(graphs, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(num_features=3, num_outputs=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "        print(out.shape)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function any(iterable, /)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[50, 3], edge_index=[2, 123], y=[4], batch=[50], ptr=[5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 2, 2],\n",
       "        [6, 0, 4, 8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index[:, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of size N by F\n",
    "tensor = torch.randn(5, 3)  # N=5, F=3\n",
    "\n",
    "# Generate random permutation indices\n",
    "perm_indices = torch.randperm(tensor.size(0))  # Random permutation of indices along dimension 0 (rows)\n",
    "\n",
    "# Permute rows of the tensor\n",
    "permuted_tensor = torch.index_select(tensor, 0, perm_indices)\n",
    "\n",
    "print(\"Original Tensor:\")\n",
    "print(tensor)\n",
    "print(\"\\nPermuted Tensor (Randomly Permuted Rows):\")\n",
    "print(permuted_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2, 3]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state = torch.randn(4, 5)  # State tensor\n",
    "\n",
    "\n",
    "gnn_features = torch.randn(4, 2, 3)  # GNN output features\n",
    "done = torch.Tensor([1, 0, 0, 0]).reshape(-1, 1)\n",
    "gnn_features.shape, done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape gnn_features from (10, 5, 3) to (10*5, 3) in place\n",
    "gnn_features_reshaped = gnn_features.view(-1, gnn_features.size(-1))\n",
    "gnn_features_reshaped.shape\n",
    "\n",
    "\n",
    "done_expanded = done.expand(gnn_features.shape[0], -1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
