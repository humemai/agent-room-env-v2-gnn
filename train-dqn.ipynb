{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MM / explore with random sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "0it [00:00, ?it/s]/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:168: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "> \u001b[0;32m/home/tk/repos/agent-room-env-v2-gnn/agent/dqn/nn/gnn.py\u001b[0m(286)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    284 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    285 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 286 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mgnn_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    287 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    288 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "DataBatch(x=[60, 32], edge_index=[2, 87], short_triples=[8], agent_node=[8], batch=[60], ptr=[9])\n",
      "DataBatch(x=[60, 32], edge_index=[2, 87], short_triples=[8], agent_node=[8], batch=[60], ptr=[9])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
      "        3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
      "        3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7])\n",
      "tensor([[ 0,  0,  0,  4,  0,  3,  4,  5,  3,  3,  7,  8, 10,  8,  8,  8, 11, 11,\n",
      "         11, 10, 14, 11, 15, 15, 18, 15, 20, 15, 21, 17, 17, 17, 21, 22, 22, 25,\n",
      "         26, 22, 28, 22, 29, 31, 29, 29, 29, 31, 30, 30, 30, 30, 35, 36, 37, 37,\n",
      "         37, 37, 41, 42, 39, 39, 39, 43, 41, 39, 45, 47, 46, 46, 49, 46, 46, 51,\n",
      "         51, 51, 49, 51, 53, 53, 53, 56, 53, 55, 55, 55, 56, 59, 55],\n",
      "        [ 1,  2,  3,  0,  2,  2,  3,  3,  0,  6,  3,  9,  8, 11, 12, 12, 13, 12,\n",
      "          8, 11, 11, 12, 16, 17, 15, 19, 15, 19, 15, 15, 19, 19, 17, 23, 24, 22,\n",
      "         22, 27, 22, 27, 30, 29, 32, 32, 33, 30, 32, 32, 34, 29, 30, 30, 38, 39,\n",
      "         38, 40, 37, 39, 38, 37, 38, 39, 39, 44, 46, 46, 48, 48, 46, 50, 51, 52,\n",
      "         46, 48, 51, 48, 54, 55, 54, 53, 57, 58, 54, 53, 55, 55, 54]])\n",
      "tensor([ 0,  8, 15, 22, 29, 37, 45, 53, 60])\n",
      "*** NameError: name 'exut' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [07:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import os\n",
    "from agent import DQNAgent\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Number of combinations you want\n",
    "num_combinations = 100  # Change this to however many combinations you need\n",
    "\n",
    "# default\n",
    "room_size = \"xl-different-prob\"\n",
    "capacity_max = 12\n",
    "batch_size = 8\n",
    "terminates_at = 9\n",
    "num_iterations = (terminates_at + 1) * 100\n",
    "validation_starts_at = num_iterations // 2\n",
    "\n",
    "prob_type = (\n",
    "    \"non-equal-object-probs\" if \"different-prob\" in room_size else \"equal-object-probs\"\n",
    ")\n",
    "root_path = (\n",
    "    f\"./training-results/{prob_type}/dqn/room_size={room_size}/capacity={capacity_max}/\"\n",
    ")\n",
    "\n",
    "# root_path = \"training-results/TRASH\"\n",
    "\n",
    "# random\n",
    "test_seed_ = [i for i in range(num_combinations)]\n",
    "target_update_interval_ = [10]\n",
    "min_epsilon_ = [0.1]\n",
    "gamma_ = [0.8, 0.9, 0.99]\n",
    "semantic_decay_factor_ = [0.7, 0.9, 0.99]\n",
    "pretrain_semantic_ = [False]\n",
    "\n",
    "# Weights for agent_capacity_ elements\n",
    "replay_buffer_size_ = [\n",
    "    num_iterations,\n",
    "    num_iterations // 2,\n",
    "]\n",
    "warm_start_ = [\n",
    "    num_iterations // 2,\n",
    "    num_iterations // 4,\n",
    "    num_iterations // 10,\n",
    "]\n",
    "\n",
    "\n",
    "# Generate all combinations\n",
    "params_all = list(\n",
    "    itertools.product(\n",
    "        test_seed_,\n",
    "        target_update_interval_,\n",
    "        min_epsilon_,\n",
    "        gamma_,\n",
    "        semantic_decay_factor_,\n",
    "        pretrain_semantic_,\n",
    "        replay_buffer_size_,\n",
    "        warm_start_,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Random combinations with weighted agent_capacity_\n",
    "random_combinations = random.sample(params_all, num_combinations)\n",
    "\n",
    "for i, params in tqdm(enumerate(random_combinations)):\n",
    "    (\n",
    "        test_seed,\n",
    "        target_update_interval,\n",
    "        min_epsilon,\n",
    "        gamma,\n",
    "        semantic_decay_factor,\n",
    "        pretrain_semantic,\n",
    "        replay_buffer_size,\n",
    "        warm_start,\n",
    "    ) = params\n",
    "\n",
    "    params_dict = {\n",
    "        \"env_str\": \"room_env:RoomEnv-v2\",\n",
    "        \"num_iterations\": num_iterations,\n",
    "        \"replay_buffer_size\": replay_buffer_size,\n",
    "        \"validation_starts_at\": validation_starts_at,\n",
    "        \"warm_start\": warm_start,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"target_update_interval\": target_update_interval,\n",
    "        \"epsilon_decay_until\": num_iterations,\n",
    "        \"max_epsilon\": 1.0,\n",
    "        \"min_epsilon\": min_epsilon,\n",
    "        \"gamma\": gamma,\n",
    "        \"capacity\": {\"long\": capacity_max, \"short\": 15},\n",
    "        \"pretrain_semantic\": pretrain_semantic,\n",
    "        \"semantic_decay_factor\": semantic_decay_factor,\n",
    "        \"dqn_params\": {\n",
    "            \"embedding_dim\": 32,\n",
    "            \"num_layers_GNN\": 2,\n",
    "            \"num_hidden_layers_MLP\": 1,\n",
    "            \"dueling_dqn\": True,\n",
    "        },\n",
    "        \"num_samples_for_results\": {\"val\": 5, \"test\": 10},\n",
    "        \"validation_interval\": 5,\n",
    "        \"plotting_interval\": 50,\n",
    "        \"train_seed\": test_seed + 5,\n",
    "        \"test_seed\": test_seed,\n",
    "        \"device\": \"cpu\",\n",
    "        \"qa_function\": \"latest_strongest\",\n",
    "        \"env_config\": {\n",
    "            \"question_prob\": 1.0,\n",
    "            \"terminates_at\": terminates_at,\n",
    "            \"randomize_observations\": \"all\",\n",
    "            \"room_size\": room_size,\n",
    "            \"rewards\": {\"correct\": 1, \"wrong\": 0, \"partial\": 0},\n",
    "            \"make_everything_static\": False,\n",
    "            \"num_total_questions\": 1000,\n",
    "            \"question_interval\": 1,\n",
    "            \"include_walls_in_observations\": True,\n",
    "        },\n",
    "        \"ddqn\": True,\n",
    "        \"default_root_dir\": root_path,\n",
    "    }\n",
    "\n",
    "    agent = DQNAgent(**params_dict)\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fixed combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import os\n",
    "from agent import DQNAgent\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "room_size = \"xl-different-prob\"\n",
    "terminates_at = 99\n",
    "num_iterations = (terminates_at + 1) * 100\n",
    "replay_buffer_size = num_iterations // 2\n",
    "validation_starts_at = num_iterations // 2\n",
    "warm_start = num_iterations // 4\n",
    "batch_size = 32\n",
    "target_update_interval = 10\n",
    "gamma = 0.9\n",
    "semantic_decay_factor = 0.9\n",
    "\n",
    "for capacity_max in [24, 12, 6, 48]:\n",
    "    prob_type = (\n",
    "        \"non-equal-object-probs\"\n",
    "        if \"different-prob\" in room_size\n",
    "        else \"equal-object-probs\"\n",
    "    )\n",
    "    root_path = (\n",
    "        f\"./training-results/{prob_type}/dqn/\"\n",
    "        f\"room_size={room_size}/capacity={capacity_max}/\"\n",
    "    )\n",
    "    for pretrain_semantic in [False, \"include_walls\", \"exclude_walls\"]:\n",
    "        for test_seed in [0, 1, 2, 3, 4]:\n",
    "            params_dict = {\n",
    "                \"env_str\": \"room_env:RoomEnv-v2\",\n",
    "                \"num_iterations\": num_iterations,\n",
    "                \"replay_buffer_size\": replay_buffer_size,\n",
    "                \"validation_starts_at\": validation_starts_at,\n",
    "                \"warm_start\": warm_start,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"target_update_interval\": target_update_interval,\n",
    "                \"epsilon_decay_until\": num_iterations,\n",
    "                \"max_epsilon\": 1.0,\n",
    "                \"min_epsilon\": 0.1,\n",
    "                \"gamma\": gamma,\n",
    "                \"capacity\": {\"long\": capacity_max, \"short\": 15},\n",
    "                \"pretrain_semantic\": pretrain_semantic,\n",
    "                \"semantic_decay_factor\": semantic_decay_factor,\n",
    "                \"dqn_params\": {\n",
    "                    \"embedding_dim\": 8,\n",
    "                    \"num_layers_GNN\": 2,\n",
    "                    \"num_hidden_layers_MLP\": 1,\n",
    "                    \"dueling_dqn\": True,\n",
    "                },\n",
    "                \"num_samples_for_results\": {\"val\": 5, \"test\": 10},\n",
    "                \"validation_interval\": 5,\n",
    "                \"plotting_interval\": 50,\n",
    "                \"train_seed\": test_seed + 5,\n",
    "                \"test_seed\": test_seed,\n",
    "                \"device\": \"cpu\",\n",
    "                \"qa_function\": \"latest_strongest\",\n",
    "                \"env_config\": {\n",
    "                    \"question_prob\": 1.0,\n",
    "                    \"terminates_at\": terminates_at,\n",
    "                    \"randomize_observations\": \"all\",\n",
    "                    \"room_size\": room_size,\n",
    "                    \"rewards\": {\"correct\": 1, \"wrong\": 0, \"partial\": 0},\n",
    "                    \"make_everything_static\": False,\n",
    "                    \"num_total_questions\": 1000,\n",
    "                    \"question_interval\": 1,\n",
    "                    \"include_walls_in_observations\": True,\n",
    "                },\n",
    "                \"ddqn\": True,\n",
    "                \"default_root_dir\": root_path,\n",
    "            }\n",
    "\n",
    "            agent = DQNAgent(**params_dict)\n",
    "            agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
