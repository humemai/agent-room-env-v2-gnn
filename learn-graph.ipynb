{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 8])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nll_loss_nd(): argument 'target' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 83\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.virtualenvs/agent-room-env-v2-gnn/lib/python3.10/site-packages/torch/nn/functional.py:2729\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2728\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: nll_loss_nd(): argument 'target' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    class GCNConv(\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool | None = None,\n",
    "        normalize: bool = True,\n",
    "        bias: bool = True,\n",
    "        **kwargs: Any\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, num_outputs):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_outputs)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Pool node features within each graph to a single vector\n",
    "        # x = global_mean_pool(x, batch)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generate some example data\n",
    "def create_random_graph_data(\n",
    "    num_node_features, num_classes=None, min_nodes=5, max_nodes=20\n",
    "):\n",
    "    num_nodes = np.random.randint(\n",
    "        min_nodes, max_nodes + 1\n",
    "    )  # Randomly choose the number of nodes\n",
    "    edge_prob = 0.2  # Probability of edge creation between any two nodes\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j and np.random.rand() < edge_prob:\n",
    "                edge_index.append([i, j])\n",
    "    edge_index = (\n",
    "        torch.tensor(edge_index).t().contiguous()\n",
    "    )  # Transpose and make contiguous\n",
    "    x = torch.randn(num_nodes, num_node_features)  # Node features\n",
    "    # y = torch.randint(0, num_classes, (1,)).item()  # Graph-level label\n",
    "    # return Data(x=x, edge_index=edge_index, y=y)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "num_graphs = 4\n",
    "\n",
    "# Use the new function to create a dataset with more varied graph sizes\n",
    "graphs = [create_random_graph_data(3, 2) for _ in range(num_graphs)]\n",
    "\n",
    "# DataLoader for batching graphs\n",
    "loader = DataLoader(graphs, batch_size=4, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(num_features=3, num_outputs=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "        print(out.shape)\n",
    "\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[7, 3], edge_index=[2, 10]),\n",
       " Data(x=[18, 3], edge_index=[2, 62]),\n",
       " Data(x=[5, 3], edge_index=[2, 5]),\n",
       " Data(x=[7, 3], edge_index=[2, 14])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 6, 6],\n",
       "        [4, 6, 0, 2, 4, 0, 6, 0, 0, 1, 2, 6, 0, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[-1].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[37, 3], edge_index=[2, 91], batch=[37], ptr=[5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8557,  1.6845, -0.5340],\n",
       "        [-0.3092, -1.7935, -1.5452],\n",
       "        [ 0.3552,  0.0205, -0.5432],\n",
       "        [-0.3292,  0.1938,  0.0675],\n",
       "        [ 1.5706,  0.8971,  0.3783],\n",
       "        [-0.7358, -1.5291,  1.9143],\n",
       "        [-0.4175,  1.9325,  0.4126],\n",
       "        [-0.3053,  0.1060,  1.8944],\n",
       "        [-0.0402, -0.1196,  1.7489],\n",
       "        [ 0.5083, -0.6034, -1.2236],\n",
       "        [-1.0666, -0.8047, -0.5614],\n",
       "        [ 1.0300, -0.5257, -0.5523],\n",
       "        [ 0.2052,  0.0303,  1.3498],\n",
       "        [ 0.7831,  0.4623,  0.8327],\n",
       "        [-1.0730, -0.0708,  0.5925],\n",
       "        [-0.8542,  0.4183, -0.6244],\n",
       "        [-0.3648, -0.3940,  0.8341],\n",
       "        [-0.5207,  0.0608, -0.5262],\n",
       "        [ 0.3114,  1.6071, -0.3523],\n",
       "        [ 1.2595,  0.3296, -0.7364],\n",
       "        [ 0.2573, -0.1825,  0.9415],\n",
       "        [-3.1771, -1.8843,  0.6215],\n",
       "        [ 0.8237, -0.9621,  0.6471],\n",
       "        [ 1.0536, -0.5551,  0.3413],\n",
       "        [-0.4691, -1.2372,  0.2933],\n",
       "        [ 0.0110, -1.7186,  2.4158],\n",
       "        [-0.8785, -0.6887, -0.7834],\n",
       "        [-0.4968, -1.8187, -1.2229],\n",
       "        [ 0.5046,  0.6217,  1.3844],\n",
       "        [ 0.1512,  2.8900, -0.4034],\n",
       "        [-0.7415, -0.6680, -0.2751],\n",
       "        [ 0.2226, -0.3119,  1.0615],\n",
       "        [ 0.7083, -3.0584, -0.3953],\n",
       "        [ 0.8941, -0.6031, -0.4385],\n",
       "        [-0.4355, -0.1513,  0.9564],\n",
       "        [ 1.2078, -0.9378,  0.1844],\n",
       "        [-0.5283, -0.7617,  0.3894]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  2,  3,  4,  4,  4,  5,  5,  6,  7,  7,  8,  8,  8,  8,  9,  9,\n",
       "          9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 12, 12, 12, 12, 12, 13, 14, 14,\n",
       "         14, 14, 14, 14, 15, 15, 15, 15, 16, 17, 17, 17, 18, 18, 18, 18, 18, 18,\n",
       "         19, 19, 19, 19, 19, 19, 20, 20, 20, 21, 21, 21, 21, 22, 23, 24, 24, 24,\n",
       "         25, 26, 26, 28, 28, 30, 30, 31, 31, 31, 32, 32, 33, 34, 34, 34, 34, 36,\n",
       "         36],\n",
       "        [ 2,  1,  5,  6,  2,  5,  6,  2,  3,  3, 13, 20, 14, 16, 17, 19, 10, 13,\n",
       "         21, 22, 23,  7, 11, 15, 23,  7, 12, 18, 13, 14, 16, 17, 18, 17,  7,  9,\n",
       "         10, 18, 21, 22,  9, 10, 17, 18, 22, 10, 18, 19,  9, 15, 16, 20, 23, 24,\n",
       "          9, 11, 13, 16, 23, 24,  7, 13, 17, 13, 15, 17, 23, 11, 11,  9, 10, 17,\n",
       "         26, 25, 29, 25, 26, 34, 36, 30, 32, 34, 30, 36, 30, 30, 31, 32, 36, 30,\n",
       "         35]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
